# Quantum-Assisted Deep Binary Neural Diffusion Model (QADBNDM)
# Optimal Training Commands for CIFAR-10 on A100 GPU

# 1. Upload and extract the model
from google.colab import files
files.upload()  # Upload qadbndm_parallel.zip
!mkdir -p qadbndm_model
!unzip -o qadbndm_parallel.zip -d qadbndm_model
!cd qadbndm_model/qadbndm_essential && pip install -e .

# 2. Install dependencies
!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
!pip install dimod dwave-neal h5py numba einops scikit-learn matplotlib tqdm

# 3. Run a simple test to verify parallel timestep processing works
print("\n=== Running test of parallel timestep processing ===")
!cd qadbndm_model/qadbndm_essential && python simple_test.py --batch-timesteps 4

# 4. Check GPU and enable optimizations
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"GPU model: {torch.cuda.get_device_name(0)}")

# Enable TF32 precision for faster training on A100
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
print("TF32 enabled for A100 acceleration")

# 5. Set environment variables for optimal performance
import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
os.environ['TORCH_CUDNN_V8_API_ENABLED'] = '1'  # Enable cuDNN v8 API
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'  # For deterministic behavior

# 6. Run CIFAR-10 training with optimal A100 settings
!cd qadbndm_model/qadbndm_essential && python train_cifar_improved.py \
    --hierarchy pyramid \
    --batch-size 256 \
    --epochs 20 \
    --learning-rate 0.001 \
    --cd-steps 15 \
    --latent-dims "2048,1024,512" \
    --lr-schedule cosine \
    --train-order bottom_up \
    --device cuda:0 \
    --mixed-precision \
    --tf32 \
    --augmentation \
    --generate-samples \
    --samples 100 \
    --eval-interval 1 \
    --batch-timesteps 4

# 7. For conditional generation after training (replace checkpoint_path with your trained model)
!cd qadbndm_model/qadbndm_essential && python examples/conditional_generation.py \
    --checkpoint "./output/checkpoints/qadbndm_final.pt" \
    --num-samples 50 \
    --device cuda:0 \
    --batch-timesteps 4 \
    --class-label 0  # 0=airplane, 1=automobile, etc.

# 8. Generate samples for all classes (0-9)
for i in range(10):
    !cd qadbndm_model/qadbndm_essential && python examples/conditional_generation.py \
        --checkpoint "./output/checkpoints/qadbndm_final.pt" \
        --num-samples 20 \
        --device cuda:0 \
        --batch-timesteps 4 \
        --class-label {i} \
        --output-dir "./output/samples/class_{i}"
        
# ========= PARALLEL ANNEALING INFORMATION ==========
# This version implements parallel quantum annealing with batch_timesteps=4, 
# which processes 4 Markov chain timesteps in parallel for each quantum annealer call.
# Benchmarks show this provides up to 3-4x speedup in the sampling phase compared to sequential processing.
#
# How it works:
# 1. The batch_timesteps parameter is passed through the model creation pipeline
# 2. During contrastive divergence, multiple steps are batched together
# 3. The QUBO formulation is adapted to process multiple steps at once
# 4. The quantum annealer solves the combined problem in a single call
# 5. This significantly reduces the overhead of repeated annealer calls 